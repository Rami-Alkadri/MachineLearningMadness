{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5729a8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7c93d338",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/2010training_dataset.csv')\n",
    "data.columns\n",
    "\n",
    "columns_to_remove = ['Games Played', 'Minutes Played', 'Possesions', 'OppPossesions', \n",
    "                     'DE', 'RankDE', 'Week_6', 'Week_12','RankAdjEM', 'AdjTempo',\n",
    "                    'OE', 'RankOE', 'RankAdjDE', 'RankAdjOE', 'Tempo_y', 'RankTempo', 'RankAdjTempo']\n",
    "data.drop(columns=columns_to_remove, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a59899e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Win %', 'PPPos', 'PAPPos', 'PPPos Margin', 'FG %', 'OppFG%',\n",
       "       '3PT FG %', '3PTPPos', 'FT %', 'FTPPos', 'OppFTPPos', 'ORPPos',\n",
       "       'Opp ORPPos', 'DRPG', 'REBPG', 'REB Margin', 'True Shooting %',\n",
       "       'Effective FG%', 'TOV %', 'TOV Forced %', 'Foul Margin', 'OppEFG',\n",
       "       'Win_last_6', 'FGM_per_poss_last_6_last_6',\n",
       "       'FGA_per_poss_last_6_last_6', 'DR_per_poss_last_6_last_6',\n",
       "       'Ast_per_poss_last_6_last_6', 'Week_1', 'Week_18', 'AdjOE', 'AdjDE',\n",
       "       'AdjEM', 'seed', 'Trapezoid', 'Diff Win', '3PM_diff', 'FT_diff',\n",
       "       'PPPos_diff', 'Orb_diff', 'Tov_diff', 'rank_diff', 'Pom_diff',\n",
       "       'TOV Margin', 'Winner'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "86275735",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with 1 PCA components: Accuracy = 0.6898\n",
      "Random Forest with 1 PCA components: Accuracy = 0.5882\n",
      "Naive Bayes with 1 PCA components: Accuracy = 0.6738\n",
      "XGBoost with 1 PCA components: Accuracy = 0.6096\n",
      "Logistic Regression with 2 PCA components: Accuracy = 0.6845\n",
      "Random Forest with 2 PCA components: Accuracy = 0.6417\n",
      "Naive Bayes with 2 PCA components: Accuracy = 0.6738\n",
      "XGBoost with 2 PCA components: Accuracy = 0.6203\n",
      "Logistic Regression with 3 PCA components: Accuracy = 0.6845\n",
      "Random Forest with 3 PCA components: Accuracy = 0.6310\n",
      "Naive Bayes with 3 PCA components: Accuracy = 0.6738\n",
      "XGBoost with 3 PCA components: Accuracy = 0.6310\n",
      "Logistic Regression with 4 PCA components: Accuracy = 0.6845\n",
      "Random Forest with 4 PCA components: Accuracy = 0.6364\n",
      "Naive Bayes with 4 PCA components: Accuracy = 0.6738\n",
      "XGBoost with 4 PCA components: Accuracy = 0.6417\n",
      "Logistic Regression with 5 PCA components: Accuracy = 0.6791\n",
      "Random Forest with 5 PCA components: Accuracy = 0.6791\n",
      "Naive Bayes with 5 PCA components: Accuracy = 0.6845\n",
      "XGBoost with 5 PCA components: Accuracy = 0.6417\n",
      "Logistic Regression with 6 PCA components: Accuracy = 0.6791\n",
      "Random Forest with 6 PCA components: Accuracy = 0.6952\n",
      "Naive Bayes with 6 PCA components: Accuracy = 0.6845\n",
      "XGBoost with 6 PCA components: Accuracy = 0.6631\n",
      "Logistic Regression with 7 PCA components: Accuracy = 0.6845\n",
      "Random Forest with 7 PCA components: Accuracy = 0.7112\n",
      "Naive Bayes with 7 PCA components: Accuracy = 0.6791\n",
      "XGBoost with 7 PCA components: Accuracy = 0.6898\n",
      "Logistic Regression with 8 PCA components: Accuracy = 0.7059\n",
      "Random Forest with 8 PCA components: Accuracy = 0.6952\n",
      "Naive Bayes with 8 PCA components: Accuracy = 0.6791\n",
      "XGBoost with 8 PCA components: Accuracy = 0.6898\n",
      "Logistic Regression with 9 PCA components: Accuracy = 0.6898\n",
      "Random Forest with 9 PCA components: Accuracy = 0.6952\n",
      "Naive Bayes with 9 PCA components: Accuracy = 0.6684\n",
      "XGBoost with 9 PCA components: Accuracy = 0.6898\n",
      "Logistic Regression with 10 PCA components: Accuracy = 0.7219\n",
      "Random Forest with 10 PCA components: Accuracy = 0.7166\n",
      "Naive Bayes with 10 PCA components: Accuracy = 0.7166\n",
      "XGBoost with 10 PCA components: Accuracy = 0.7326\n",
      "Logistic Regression with 11 PCA components: Accuracy = 0.7059\n",
      "Random Forest with 11 PCA components: Accuracy = 0.6952\n",
      "Naive Bayes with 11 PCA components: Accuracy = 0.7166\n",
      "XGBoost with 11 PCA components: Accuracy = 0.7005\n",
      "Logistic Regression with 12 PCA components: Accuracy = 0.7005\n",
      "Random Forest with 12 PCA components: Accuracy = 0.7326\n",
      "Naive Bayes with 12 PCA components: Accuracy = 0.7005\n",
      "XGBoost with 12 PCA components: Accuracy = 0.6684\n",
      "Logistic Regression with 13 PCA components: Accuracy = 0.6952\n",
      "Random Forest with 13 PCA components: Accuracy = 0.7059\n",
      "Naive Bayes with 13 PCA components: Accuracy = 0.6952\n",
      "XGBoost with 13 PCA components: Accuracy = 0.7005\n",
      "Logistic Regression with 14 PCA components: Accuracy = 0.6845\n",
      "Random Forest with 14 PCA components: Accuracy = 0.6791\n",
      "Naive Bayes with 14 PCA components: Accuracy = 0.7005\n",
      "XGBoost with 14 PCA components: Accuracy = 0.6578\n",
      "Logistic Regression with 15 PCA components: Accuracy = 0.6898\n",
      "Random Forest with 15 PCA components: Accuracy = 0.6952\n",
      "Naive Bayes with 15 PCA components: Accuracy = 0.6952\n",
      "XGBoost with 15 PCA components: Accuracy = 0.6738\n",
      "Logistic Regression with 16 PCA components: Accuracy = 0.6952\n",
      "Random Forest with 16 PCA components: Accuracy = 0.6631\n",
      "Naive Bayes with 16 PCA components: Accuracy = 0.6845\n",
      "XGBoost with 16 PCA components: Accuracy = 0.6738\n",
      "Logistic Regression with 17 PCA components: Accuracy = 0.6898\n",
      "Random Forest with 17 PCA components: Accuracy = 0.6471\n",
      "Naive Bayes with 17 PCA components: Accuracy = 0.6845\n",
      "XGBoost with 17 PCA components: Accuracy = 0.7059\n",
      "Logistic Regression with 18 PCA components: Accuracy = 0.7059\n",
      "Random Forest with 18 PCA components: Accuracy = 0.6738\n",
      "Naive Bayes with 18 PCA components: Accuracy = 0.6952\n",
      "XGBoost with 18 PCA components: Accuracy = 0.6952\n",
      "Logistic Regression with 19 PCA components: Accuracy = 0.6952\n",
      "Random Forest with 19 PCA components: Accuracy = 0.6791\n",
      "Naive Bayes with 19 PCA components: Accuracy = 0.7059\n",
      "XGBoost with 19 PCA components: Accuracy = 0.6845\n",
      "Logistic Regression with 20 PCA components: Accuracy = 0.6952\n",
      "Random Forest with 20 PCA components: Accuracy = 0.6578\n",
      "Naive Bayes with 20 PCA components: Accuracy = 0.6952\n",
      "XGBoost with 20 PCA components: Accuracy = 0.7219\n",
      "\n",
      "The best model is XGBoost with 10 PCA components, achieving an accuracy of 0.7326.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import xgboost as xgb\n",
    "\n",
    "# Assuming X and y are defined\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "models = [\n",
    "    ('Logistic Regression', LogisticRegression(solver='lbfgs', max_iter=1000)),\n",
    "    ('Random Forest', RandomForestClassifier(n_estimators=75, criterion='entropy')),\n",
    "    ('Naive Bayes', GaussianNB()),\n",
    "    ('XGBoost', xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss'))\n",
    "]\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize variables to store the best model's information\n",
    "max_accuracy = 0\n",
    "best_model_name = None\n",
    "best_pca_n_components = None\n",
    "best_pipeline = None\n",
    "\n",
    "for n_components in range(1, min(20, X_train.shape[1]) + 1):\n",
    "    # Fit PCA on the training data for the current number of components\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    \n",
    "    for model_name, model in models:\n",
    "        # Create a pipeline for the current model\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()), \n",
    "            ('pca', PCA(n_components=n_components)),\n",
    "            ('model', model)\n",
    "        ])\n",
    "        \n",
    "        # Train the model pipeline on the training data\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict probabilities for the positive class on the test data\n",
    "        y_test_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Threshold probabilities at 0.5 to determine class predictions\n",
    "        y_pred = (y_test_proba > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate accuracy for the current model\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        print(f\"{model_name} with {n_components} PCA components: Accuracy = {accuracy:.4f}\")\n",
    "        \n",
    "        # Update the best model if the current model has higher accuracy\n",
    "        if accuracy > max_accuracy:\n",
    "            max_accuracy = accuracy\n",
    "            best_model_name = model_name\n",
    "            best_pca_n_components = n_components\n",
    "            best_pipeline = pipeline\n",
    "\n",
    "print(f\"\\nThe best model is {best_model_name} with {best_pca_n_components} PCA components, achieving an accuracy of {max_accuracy:.4f}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e542b716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the StandardScaler instance\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "# Save the PCA instance\n",
    "with open('pca.pkl', 'wb') as f:\n",
    "    pickle.dump(pca, f)\n",
    "\n",
    "# Save the best performing pipeline (which includes the best model)\n",
    "with open('best_model_pipeline.pkl', 'wb') as f:\n",
    "    pickle.dump(pipeline, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5fbe63db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1245, 43)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
